Content moderation on X combines automatic approaches and human evaluators. According to their transparency report, X uses heuristic and automatic models (automatic language processing, computer vision, etc.) to detect potentially prohibited content. Human moderators are then responsible for verifying that the detected content is indeed prohibited. The combination of human moderators and algorithms is also used to evaluate and improve moderation models. 